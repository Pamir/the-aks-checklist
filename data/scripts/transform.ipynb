{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2: take the old items and convert them to the format we need to make it work in FTA checklist\n",
    "import uuid\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "need_to_compare = False # variable used to identify if the checklist needs to be compared with the FTA checklist\n",
    "# get the mapping table that converts filename to the correct category name in FTA's checklist\n",
    "filename_map = pd.read_csv('filename_map.csv')\n",
    "filename_map.to_dict(\"list\")\n",
    "\n",
    "# convert the mapping table to a mapping dictionary that can more easily be used\n",
    "filename_map_dict = {}\n",
    "for filename, actualname in zip(filename_map['filename'],filename_map['actualname']):\n",
    "    filename_map_dict[filename] = actualname\n",
    "\n",
    "def get_subcategory(tags):\n",
    "    \"\"\"function to get the first tag that isnt all\"\"\"\n",
    "    relevant_tags = [x for x in tags if x != \"all\"]\n",
    "    if len(relevant_tags) > 0:\n",
    "        return relevant_tags[0].title()\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "def get_link(entry):\n",
    "    \"\"\" function to get documentation link \"\"\"\n",
    "    if 'documentation' in entry.keys():\n",
    "        try:\n",
    "            context = entry['documentation'][0]\n",
    "        except IndexError:\n",
    "            context = {\"title\":\"none available\",\"url\":\"\"}        \n",
    "    elif 'tools' in entry.keys():\n",
    "        try:\n",
    "            context = entry['tools'][0]\n",
    "        except IndexError:\n",
    "            context = {\"title\":\"none available\",\"url\":\"\"}\n",
    "    else:\n",
    "        context = {\"title\":\"none available\",\"url\":\"\"}\n",
    "    return context[\"url\"]\n",
    "\n",
    "def transform(item,filename):\n",
    "    transformed_item = dict()\n",
    "    transformed_item['text'] =  item['title']\n",
    "    transformed_item[\"description\"] = item[\"description\"]\n",
    "    transformed_item['subcategory'] =  get_subcategory(item['tags'])\n",
    "    try:\n",
    "        transformed_item['category'] = filename_map_dict[filename]\n",
    "    except KeyError:\n",
    "        print(f'cant find {filename} in the dictionary')\n",
    "        pass\n",
    "    transformed_item['guid'] = str(uuid.uuid4())\n",
    "    transformed_item['severity'] = item['priority']\n",
    "    transformed_item['link'] = get_link(item)\n",
    "    return transformed_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'../en/items/'\n",
    "# list to store files\n",
    "filenames = []\n",
    "# Iterate directory\n",
    "for file in os.listdir(dir_path):\n",
    "    # check only json files\n",
    "    if file.endswith('.json'):\n",
    "        filenames.append(file)\n",
    "# print(filenames)\n",
    "\n",
    "## get the items in all the different files in the dir_path. start by initializing the transformed\n",
    "# items list\n",
    "items = []\n",
    "# get all the categories available in the mapping table so files in the dir not in the \n",
    "# considered categories (eg cluster_setup) are not considered\n",
    "categories = filename_map_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application.json',\n",
       " 'bc_dr.json',\n",
       " 'cluster_multi.json',\n",
       " 'cluster_security.json',\n",
       " 'container.json',\n",
       " 'identity.json',\n",
       " 'networking.json',\n",
       " 'operations.json',\n",
       " 'resource_management.json',\n",
       " 'storage.json',\n",
       " 'windows.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished application\n",
      "finished bc_dr\n",
      "finished cluster_multi\n",
      "finished cluster_security\n",
      "finished container\n",
      "finished identity\n",
      "finished networking\n",
      "finished operations\n",
      "finished resource_management\n",
      "finished storage\n",
      "finished windows\n"
     ]
    }
   ],
   "source": [
    "# iterate over the files\n",
    "for file in filenames:\n",
    "    # remove .json from filename\n",
    "    file2 = file.split(\".\")[0]\n",
    "    # check to make sure that the filename is in categories\n",
    "    if file2 in categories:\n",
    "        # get the content of the file\n",
    "        with open(dir_path + file) as f:\n",
    "            content = json.load(f)\n",
    "        # transform each item in the file to the FT data format\n",
    "        for item in content:\n",
    "            transformed_item = transform(item,file2)\n",
    "            if need_to_compare:\n",
    "                transformed_item[\"source\"] = 'the-aks-checklist' # temporary step to help us identify missing items from the-aks-checklist\n",
    "            items.append(transformed_item)\n",
    "        print(f\"finished {file2}\")    \n",
    "    else:\n",
    "        print(f'cant find {file2} in the dictionary')\n",
    "        pass\n",
    "\n",
    "# finally we pull the ft data and append it to the transformed data then save it in the ft file. this need only be ran once\n",
    "# with open(\"./ft_data.json\") as f:\n",
    "#     content = json.load(f)\n",
    "#     combined_list = content[\"items\"] + items\n",
    "#     content[\"items\"] = combined_list\n",
    "\n",
    "with open(\"aks_checklist.en.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(items, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# lets get the combined list as a csv\n",
    "if need_to_compare:\n",
    "    pd.DataFrame(combined_list).to_csv(\"combined.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bc And Dr'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"BC and DR\".title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Application'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"application\".title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5bf244bc7b828d69e99b531c349d842dbdb7a5a820ff61d883606b71f593f4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
